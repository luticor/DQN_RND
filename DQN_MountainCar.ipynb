{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of the Problem\n",
    "![](MountainCar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "#Test out environment and grab state/action space parameters\n",
    "env = gym.make('MountainCar-v0')\n",
    "n_actions = env.action_space.n\n",
    "shape_obs = env.observation_space.shape\n",
    "env.close()\n",
    "#Action must be 0 (left), 1 (nothing), or 2 (right)\n",
    "\n",
    "#Define initial/default parameters\n",
    "class iparams: #initial parameters\n",
    "    def __init__(self):\n",
    "        #default hyperparameters\n",
    "        self.buffersize = int(1E6) #Max Number of data points stored in buffer\n",
    "        self.batchsize = 128 #BatchSize\n",
    "        self.shape_obs = shape_obs\n",
    "        self.n_actions = n_actions\n",
    "        self.nH = [120,120,120]\n",
    "        self.nA = n_actions\n",
    "        self.nS = shape_obs[0]\n",
    "        self.nC = 32 #Dimensionality of RND Network Code\n",
    "        self.gamma = 0.99 #Time discount factor\n",
    "        self.lr = 0.0005 #Adam Optimizer Learning Rate\n",
    "\n",
    "\n",
    "params = iparams()\n",
    "\n",
    "#My favorite print function - repeats commands, doesn't always work with PyTorch\n",
    "def printo(string):\n",
    "    print(string,eval(string))\n",
    "\n",
    "#Plotting mountain car trajectory from observations\n",
    "def plot_trajectory(lst_obs):\n",
    "    obs_vec = np.array(lst_obs)\n",
    "    plt.figure(figsize=(10,3))\n",
    "    time_addition = np.array(range(np.shape(obs_vec)[0]))/500\n",
    "    default = np.array(range(1000))/1000*1.8-1.2\n",
    "    plt.plot(obs_vec[:,0],np.sin(3*obs_vec[:,0])+time_addition,'.',\n",
    "        label='Cart Trajectory')\n",
    "    plt.plot(default,np.sin(3*default),label='Ground')\n",
    "    plt.xlim([-1.2,0.6])\n",
    "    plt.ylim([-1,1.1])\n",
    "    plt.xlabel('Horizontal Position')\n",
    "    plt.ylabel('Vertical with Time Addition')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#Data buffer for storing data\n",
    "class bufferobject:\n",
    "    def __init__(self,params):\n",
    "        self.buffersize=params.buffersize\n",
    "        self.defaultbatch = params.batchsize\n",
    "        self.index = 0\n",
    "        #obs_dims = (self.buffersize,) + shape_obs\n",
    "        #self.state = np.zeros(size=obs_dims)\n",
    "        #self.actions = np\n",
    "        #self.state = deque(maxlen=self.buffersize)\n",
    "        #self.action = deque(maxlen=self.buffersize)\n",
    "        #self.reward = deque(maxlen=self.buffersize)\n",
    "        #self.nextstate = deque(maxlen=self.buffersize)\n",
    "        self.experience = deque(maxlen=self.buffersize)\n",
    "        self.recentexperience = deque(maxlen=self.defaultbatch*4)\n",
    "\n",
    "    def add(self,s,a,r,s_,d):\n",
    "        #self.state.append(s)\n",
    "        #self.action.append(a)\n",
    "        #self.reward.append(r)\n",
    "        #self.nextstate.append(s_)\n",
    "        #self.index +=1\n",
    "        self.experience.append([s,a,r,s_,d])\n",
    "        self.recentexperience.append([s,a,r,s_,d])\n",
    "        self.index +=1\n",
    "\n",
    "    \n",
    "    def sample(self,batch = 32):\n",
    "        #vec = range(min(self.index,self.buffersize))\n",
    "        #ind = np.random.choice(a=vec,b=batchsize)\n",
    "        #self.experience.sample\n",
    "        K = min(self.index,self.buffersize,batch)\n",
    "        samples = random.sample(self.experience, K)\n",
    "        \n",
    "        s,a,r,s_,d = zip(*samples)\n",
    "        s = torch.tensor( s, dtype=torch.float)\n",
    "        a = torch.tensor( a, dtype=torch.long).view(K, -1)\n",
    "        r = torch.tensor( r, dtype=torch.float).view(K, -1)\n",
    "        s_ = torch.tensor( s_, dtype=torch.float)\n",
    "        d = torch.tensor( d, dtype=torch.float)\n",
    "        return s,a,r,s_,d\n",
    "\n",
    "    def sample_recent(self,batch = 32):\n",
    "        K = min(self.index,self.buffersize,batch)\n",
    "        samples = random.sample(self.recentexperience, K)\n",
    "        \n",
    "        s,a,r,s_,d = zip(*samples)\n",
    "        s = torch.tensor( s, dtype=torch.float)\n",
    "        a = torch.tensor( a, dtype=torch.long).view(K, -1)\n",
    "        r = torch.tensor( r, dtype=torch.float).view(K, -1)\n",
    "        s_ = torch.tensor( s_, dtype=torch.float)\n",
    "        d = torch.tensor( d, dtype=torch.float)\n",
    "        return s,a,r,s_,d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test Episode for Environment/Buffer\n",
    "env = gym.make('MountainCar-v0')\n",
    "s = env.reset()\n",
    "buffer = bufferobject(params)\n",
    "#printo('env.action_space')\n",
    "#printo('env.observation_space')\n",
    "#Action must be 0 (left), 1 (nothing), or 2 (right)\n",
    "#observation, reward, done, _  = env.step(2) \n",
    "#printo('observation, reward, done')\n",
    "\n",
    "lst_obs = []\n",
    "d=False\n",
    "while d==False:\n",
    "\n",
    "    a = np.random.choice([0,1,2])\n",
    "    s_, r, d, _ = env.step(a)\n",
    "    buffer.add(s,a,r,s_,d)\n",
    "    lst_obs.append(s)\n",
    "    s =  s_\n",
    "    _,actions,_,_,_ = buffer.sample(batch=5)\n",
    "    #printo('actions')\n",
    "plot_trajectory(lst_obs)\n",
    "stest = s\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action tensor([2])\n",
      "action tensor([2])\n",
      "action tensor([2])\n",
      "action tensor([1])\n",
      "iter =  0  loss =  tensor(0.8434, grad_fn=<MeanBackward0>)  distance =  tensor(0.9169)\n",
      "iter =  1  loss =  tensor(0.7251, grad_fn=<MeanBackward0>)  distance =  tensor(0.8502)\n",
      "iter =  2  loss =  tensor(0.6373, grad_fn=<MeanBackward0>)  distance =  tensor(0.7870)\n",
      "iter =  3  loss =  tensor(0.5398, grad_fn=<MeanBackward0>)  distance =  tensor(0.7274)\n",
      "iter =  4  loss =  tensor(0.4692, grad_fn=<MeanBackward0>)  distance =  tensor(0.6906)\n",
      "iter =  5  loss =  tensor(0.3958, grad_fn=<MeanBackward0>)  distance =  tensor(0.6348)\n",
      "iter =  6  loss =  tensor(0.3348, grad_fn=<MeanBackward0>)  distance =  tensor(0.5776)\n",
      "iter =  7  loss =  tensor(0.2812, grad_fn=<MeanBackward0>)  distance =  tensor(0.5271)\n",
      "iter =  8  loss =  tensor(0.2392, grad_fn=<MeanBackward0>)  distance =  tensor(0.4877)\n",
      "iter =  9  loss =  tensor(0.1995, grad_fn=<MeanBackward0>)  distance =  tensor(0.4398)\n",
      "iter =  10  loss =  tensor(0.1659, grad_fn=<MeanBackward0>)  distance =  tensor(0.4030)\n",
      "iter =  11  loss =  tensor(0.1367, grad_fn=<MeanBackward0>)  distance =  tensor(0.3710)\n",
      "iter =  12  loss =  tensor(0.1149, grad_fn=<MeanBackward0>)  distance =  tensor(0.3336)\n",
      "iter =  13  loss =  tensor(0.0947, grad_fn=<MeanBackward0>)  distance =  tensor(0.3022)\n",
      "iter =  14  loss =  tensor(0.0752, grad_fn=<MeanBackward0>)  distance =  tensor(0.2798)\n",
      "iter =  15  loss =  tensor(0.0618, grad_fn=<MeanBackward0>)  distance =  tensor(0.2484)\n",
      "iter =  16  loss =  tensor(0.0500, grad_fn=<MeanBackward0>)  distance =  tensor(0.2224)\n",
      "iter =  17  loss =  tensor(0.0411, grad_fn=<MeanBackward0>)  distance =  tensor(0.2106)\n",
      "iter =  18  loss =  tensor(0.0341, grad_fn=<MeanBackward0>)  distance =  tensor(0.1788)\n",
      "iter =  19  loss =  tensor(0.0266, grad_fn=<MeanBackward0>)  distance =  tensor(0.1666)\n",
      "iter =  20  loss =  tensor(0.0220, grad_fn=<MeanBackward0>)  distance =  tensor(0.1468)\n",
      "iter =  21  loss =  tensor(0.0176, grad_fn=<MeanBackward0>)  distance =  tensor(0.1339)\n",
      "iter =  22  loss =  tensor(0.0140, grad_fn=<MeanBackward0>)  distance =  tensor(0.1190)\n",
      "iter =  23  loss =  tensor(0.0123, grad_fn=<MeanBackward0>)  distance =  tensor(0.1094)\n",
      "iter =  24  loss =  tensor(0.0107, grad_fn=<MeanBackward0>)  distance =  tensor(0.1050)\n",
      "iter =  25  loss =  tensor(0.0093, grad_fn=<MeanBackward0>)  distance =  tensor(0.0974)\n",
      "iter =  26  loss =  tensor(0.0089, grad_fn=<MeanBackward0>)  distance =  tensor(0.0952)\n",
      "iter =  27  loss =  tensor(0.0090, grad_fn=<MeanBackward0>)  distance =  tensor(0.0948)\n",
      "iter =  28  loss =  tensor(0.0092, grad_fn=<MeanBackward0>)  distance =  tensor(0.0963)\n",
      "iter =  29  loss =  tensor(0.0091, grad_fn=<MeanBackward0>)  distance =  tensor(0.0938)\n",
      "iter =  30  loss =  tensor(0.0093, grad_fn=<MeanBackward0>)  distance =  tensor(0.0964)\n",
      "iter =  31  loss =  tensor(0.0097, grad_fn=<MeanBackward0>)  distance =  tensor(0.0970)\n",
      "iter =  32  loss =  tensor(0.0094, grad_fn=<MeanBackward0>)  distance =  tensor(0.0947)\n",
      "iter =  33  loss =  tensor(0.0090, grad_fn=<MeanBackward0>)  distance =  tensor(0.0956)\n",
      "iter =  34  loss =  tensor(0.0090, grad_fn=<MeanBackward0>)  distance =  tensor(0.0903)\n",
      "iter =  35  loss =  tensor(0.0083, grad_fn=<MeanBackward0>)  distance =  tensor(0.0913)\n",
      "iter =  36  loss =  tensor(0.0075, grad_fn=<MeanBackward0>)  distance =  tensor(0.0872)\n",
      "iter =  37  loss =  tensor(0.0072, grad_fn=<MeanBackward0>)  distance =  tensor(0.0842)\n",
      "iter =  38  loss =  tensor(0.0062, grad_fn=<MeanBackward0>)  distance =  tensor(0.0786)\n",
      "iter =  39  loss =  tensor(0.0058, grad_fn=<MeanBackward0>)  distance =  tensor(0.0762)\n",
      "iter =  40  loss =  tensor(0.0049, grad_fn=<MeanBackward0>)  distance =  tensor(0.0716)\n",
      "iter =  41  loss =  tensor(0.0046, grad_fn=<MeanBackward0>)  distance =  tensor(0.0623)\n",
      "iter =  42  loss =  tensor(0.0039, grad_fn=<MeanBackward0>)  distance =  tensor(0.0649)\n",
      "iter =  43  loss =  tensor(0.0034, grad_fn=<MeanBackward0>)  distance =  tensor(0.0581)\n",
      "iter =  44  loss =  tensor(0.0030, grad_fn=<MeanBackward0>)  distance =  tensor(0.0533)\n",
      "iter =  45  loss =  tensor(0.0031, grad_fn=<MeanBackward0>)  distance =  tensor(0.0545)\n",
      "iter =  46  loss =  tensor(0.0029, grad_fn=<MeanBackward0>)  distance =  tensor(0.0517)\n",
      "iter =  47  loss =  tensor(0.0023, grad_fn=<MeanBackward0>)  distance =  tensor(0.0488)\n",
      "iter =  48  loss =  tensor(0.0021, grad_fn=<MeanBackward0>)  distance =  tensor(0.0456)\n",
      "iter =  49  loss =  tensor(0.0019, grad_fn=<MeanBackward0>)  distance =  tensor(0.0459)\n",
      "iter =  50  loss =  tensor(0.0018, grad_fn=<MeanBackward0>)  distance =  tensor(0.0409)\n",
      "iter =  51  loss =  tensor(0.0018, grad_fn=<MeanBackward0>)  distance =  tensor(0.0407)\n",
      "iter =  52  loss =  tensor(0.0016, grad_fn=<MeanBackward0>)  distance =  tensor(0.0373)\n",
      "iter =  53  loss =  tensor(0.0016, grad_fn=<MeanBackward0>)  distance =  tensor(0.0303)\n",
      "iter =  54  loss =  tensor(0.0014, grad_fn=<MeanBackward0>)  distance =  tensor(0.0376)\n",
      "iter =  55  loss =  tensor(0.0015, grad_fn=<MeanBackward0>)  distance =  tensor(0.0345)\n",
      "iter =  56  loss =  tensor(0.0012, grad_fn=<MeanBackward0>)  distance =  tensor(0.0394)\n",
      "iter =  57  loss =  tensor(0.0014, grad_fn=<MeanBackward0>)  distance =  tensor(0.0412)\n",
      "iter =  58  loss =  tensor(0.0015, grad_fn=<MeanBackward0>)  distance =  tensor(0.0359)\n",
      "iter =  59  loss =  tensor(0.0012, grad_fn=<MeanBackward0>)  distance =  tensor(0.0342)\n",
      "iter =  60  loss =  tensor(0.0012, grad_fn=<MeanBackward0>)  distance =  tensor(0.0335)\n",
      "iter =  61  loss =  tensor(0.0013, grad_fn=<MeanBackward0>)  distance =  tensor(0.0325)\n",
      "iter =  62  loss =  tensor(0.0011, grad_fn=<MeanBackward0>)  distance =  tensor(0.0340)\n",
      "iter =  63  loss =  tensor(0.0012, grad_fn=<MeanBackward0>)  distance =  tensor(0.0345)\n",
      "iter =  64  loss =  tensor(0.0010, grad_fn=<MeanBackward0>)  distance =  tensor(0.0341)\n",
      "iter =  65  loss =  tensor(0.0012, grad_fn=<MeanBackward0>)  distance =  tensor(0.0254)\n",
      "iter =  66  loss =  tensor(0.0009, grad_fn=<MeanBackward0>)  distance =  tensor(0.0294)\n",
      "iter =  67  loss =  tensor(0.0009, grad_fn=<MeanBackward0>)  distance =  tensor(0.0298)\n",
      "iter =  68  loss =  tensor(0.0008, grad_fn=<MeanBackward0>)  distance =  tensor(0.0304)\n",
      "iter =  69  loss =  tensor(0.0009, grad_fn=<MeanBackward0>)  distance =  tensor(0.0240)\n",
      "iter =  70  loss =  tensor(0.0009, grad_fn=<MeanBackward0>)  distance =  tensor(0.0263)\n",
      "iter =  71  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0230)\n",
      "iter =  72  loss =  tensor(0.0008, grad_fn=<MeanBackward0>)  distance =  tensor(0.0293)\n",
      "iter =  73  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0255)\n",
      "iter =  74  loss =  tensor(0.0008, grad_fn=<MeanBackward0>)  distance =  tensor(0.0195)\n",
      "iter =  75  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0214)\n",
      "iter =  76  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0227)\n",
      "iter =  77  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0221)\n",
      "iter =  78  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0277)\n",
      "iter =  79  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0247)\n",
      "iter =  80  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0257)\n",
      "iter =  81  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0200)\n",
      "iter =  82  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0251)\n",
      "iter =  83  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0273)\n",
      "iter =  84  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0289)\n",
      "iter =  85  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0260)\n",
      "iter =  86  loss =  tensor(0.0008, grad_fn=<MeanBackward0>)  distance =  tensor(0.0259)\n",
      "iter =  87  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0231)\n",
      "iter =  88  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0268)\n",
      "iter =  89  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0187)\n",
      "iter =  90  loss =  tensor(0.0008, grad_fn=<MeanBackward0>)  distance =  tensor(0.0231)\n",
      "iter =  91  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0255)\n",
      "iter =  92  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0280)\n",
      "iter =  93  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0266)\n",
      "iter =  94  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0212)\n",
      "iter =  95  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0248)\n",
      "iter =  96  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0251)\n",
      "iter =  97  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0254)\n",
      "iter =  98  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0205)\n",
      "iter =  99  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0220)\n",
      "iter =  100  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0193)\n",
      "iter =  101  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0220)\n",
      "iter =  102  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0214)\n",
      "iter =  103  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0201)\n",
      "iter =  104  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0237)\n",
      "iter =  105  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0202)\n",
      "iter =  106  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0300)\n",
      "iter =  107  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0219)\n",
      "iter =  108  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0281)\n",
      "iter =  109  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0202)\n",
      "iter =  110  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0227)\n",
      "iter =  111  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0249)\n",
      "iter =  112  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0156)\n",
      "iter =  113  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0153)\n",
      "iter =  114  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0259)\n",
      "iter =  115  loss =  tensor(0.0007, grad_fn=<MeanBackward0>)  distance =  tensor(0.0242)\n",
      "iter =  116  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0276)\n",
      "iter =  117  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0190)\n",
      "iter =  118  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0213)\n",
      "iter =  119  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0220)\n",
      "iter =  120  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0212)\n",
      "iter =  121  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0176)\n",
      "iter =  122  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0213)\n",
      "iter =  123  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0181)\n",
      "iter =  124  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0231)\n",
      "iter =  125  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0224)\n",
      "iter =  126  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0215)\n",
      "iter =  127  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0204)\n",
      "iter =  128  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0214)\n",
      "iter =  129  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0192)\n",
      "iter =  130  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0229)\n",
      "iter =  131  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0182)\n",
      "iter =  132  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0214)\n",
      "iter =  133  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0212)\n",
      "iter =  134  loss =  tensor(0.0006, grad_fn=<MeanBackward0>)  distance =  tensor(0.0214)\n",
      "iter =  135  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0196)\n",
      "iter =  136  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0183)\n",
      "iter =  137  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0235)\n",
      "iter =  138  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0215)\n",
      "iter =  139  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0206)\n",
      "iter =  140  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0213)\n",
      "iter =  141  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0214)\n",
      "iter =  142  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0185)\n",
      "iter =  143  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0165)\n",
      "iter =  144  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0227)\n",
      "iter =  145  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0211)\n",
      "iter =  146  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0149)\n",
      "iter =  147  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0173)\n",
      "iter =  148  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0146)\n",
      "iter =  149  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0234)\n",
      "iter =  150  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0147)\n",
      "iter =  151  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0267)\n",
      "iter =  152  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0123)\n",
      "iter =  153  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0160)\n",
      "iter =  154  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0190)\n",
      "iter =  155  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0158)\n",
      "iter =  156  loss =  tensor(0.0005, grad_fn=<MeanBackward0>)  distance =  tensor(0.0118)\n",
      "iter =  157  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0187)\n",
      "iter =  158  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0194)\n",
      "iter =  159  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0153)\n",
      "iter =  160  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0181)\n",
      "iter =  161  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0144)\n",
      "iter =  162  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0198)\n",
      "iter =  163  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0166)\n",
      "iter =  164  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0175)\n",
      "iter =  165  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0209)\n",
      "iter =  166  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0171)\n",
      "iter =  167  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0157)\n",
      "iter =  168  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0202)\n",
      "iter =  169  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0152)\n",
      "iter =  170  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0171)\n",
      "iter =  171  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0183)\n",
      "iter =  172  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0194)\n",
      "iter =  173  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0184)\n",
      "iter =  174  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0101)\n",
      "iter =  175  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0107)\n",
      "iter =  176  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0149)\n",
      "iter =  177  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0123)\n",
      "iter =  178  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0170)\n",
      "iter =  179  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0175)\n",
      "iter =  180  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0171)\n",
      "iter =  181  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0209)\n",
      "iter =  182  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0205)\n",
      "iter =  183  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0173)\n",
      "iter =  184  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0199)\n",
      "iter =  185  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0169)\n",
      "iter =  186  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0207)\n",
      "iter =  187  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0210)\n",
      "iter =  188  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0131)\n",
      "iter =  189  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0173)\n",
      "iter =  190  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0159)\n",
      "iter =  191  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0194)\n",
      "iter =  192  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0164)\n",
      "iter =  193  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0131)\n",
      "iter =  194  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0134)\n",
      "iter =  195  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0188)\n",
      "iter =  196  loss =  tensor(0.0004, grad_fn=<MeanBackward0>)  distance =  tensor(0.0165)\n",
      "iter =  197  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0187)\n",
      "iter =  198  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0177)\n",
      "iter =  199  loss =  tensor(0.0003, grad_fn=<MeanBackward0>)  distance =  tensor(0.0156)\n"
     ]
    }
   ],
   "source": [
    "#Define Q network\n",
    "class Qnet(torch.nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.nS = params.nS\n",
    "        self.nH = params.nH\n",
    "        self.nA = params.nA\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.layers.append(nn.Linear(self.nS,self.nH[0]))\n",
    "        for ind in range(len(self.nH)-1):\n",
    "            self.layers.append(nn.Linear(self.nH[ind],self.nH[ind+1]))\n",
    "        self.layers.append(nn.Linear(self.nH[-1],self.nA))\n",
    "\n",
    "        self.optim = torch.optim.Adam(self.parameters(),lr=params.lr)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x should be a tensor of size (batch,nS)\n",
    "        for ind in range(len(self.nH)-1):\n",
    "            x = nn.functional.relu(self.layers[ind](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "#Define Random Network Distillation (RND) network\n",
    "class RNDnet(torch.nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(RNDnet, self).__init__()\n",
    "        self.nS = params.nS\n",
    "        self.nH = params.nH\n",
    "        self.nA = params.nC\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.layers.append(nn.Linear(self.nS,self.nH[0]))\n",
    "        for ind in range(len(self.nH)-1):\n",
    "            self.layers.append(nn.Linear(self.nH[ind],self.nH[ind+1]))\n",
    "        self.layers.append(nn.Linear(self.nH[-1],self.nA))\n",
    "\n",
    "        self.optim = torch.optim.Adam(self.parameters(),lr=params.lr)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x should be a tensor of size (batch,nS)\n",
    "        for ind in range(len(self.nH)-1):\n",
    "            x = nn.functional.relu(self.layers[ind](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "# Separated Q function inputs and selection from the action sampling \n",
    "# I don't love the proportional implementation since the proportional involves tuned constants to make the softmax work, \n",
    "# but it choose_action does select an action with sampling functionality\n",
    "def Qs_(state,Qnet):\n",
    "    with torch.no_grad():\n",
    "        Qs = Qnet(state)\n",
    "    return Qs\n",
    "\n",
    "def Qs_mix(state,Qnet1,Qnet2,alpha=0.9):\n",
    "    with torch.no_grad():\n",
    "        Qs1 = Qnet1(state)\n",
    "        Qs2 = Qnet2(state)\n",
    "        Qmix = Qs1*alpha + Qs2*(1-alpha)\n",
    "    return Qmix\n",
    "\n",
    "def choose_action(Qs,mode='epsgreedy', epsilon=0.1):\n",
    "    #Qs should be the vector of state values\n",
    "    #state should be a tensor of size (1,nS)\n",
    "    sample = np.random.uniform()\n",
    "    if mode.casefold() == 'epsgreedy'.casefold():\n",
    "        if sample > epsilon:\n",
    "            action = torch.argmax(Qs)\n",
    "        else:\n",
    "            action = np.random.choice(np.array(range(len(Qs))))\n",
    "            action = torch.tensor(action)\n",
    "    if mode.casefold() == 'proportional'.casefold():\n",
    "            Qs_norm = Qs*5/(torch.max(Qs)-torch.min(Qs))\n",
    "            probs = torch.nn.Softmax(dim=0)(Qs_norm)\n",
    "            dist = torch.distributions.categorical.Categorical(probs=probs)\n",
    "            action = dist.sample()\n",
    "    if mode.casefold() == 'optimal'.casefold():\n",
    "        action = torch.argmax(Qs)\n",
    "    #returns a tensor of size (1)\n",
    "    return action\n",
    "\n",
    "def updateRND(RNDnetwork_target,RNDnetwork,params,batch):\n",
    "    s,a,r,s_,d = batch\n",
    "    with torch.no_grad():\n",
    "        RND_target = RNDnetwork_target(s)\n",
    "    RND_pred = RNDnetwork(s)\n",
    "    loss = torch.mean(torch.sum((RND_target-RND_pred)**2,dim=1))\n",
    "\n",
    "    RNDnetwork.optim.zero_grad()\n",
    "    loss.backward()\n",
    "    RNDnetwork.optim.step()\n",
    "\n",
    "    return RNDnetwork, loss\n",
    "    \n",
    "\n",
    "def updateQ(Qnetwork,params,batch,rewardtype='standard'):\n",
    "    #state should be a tensor of size (batchsize,nS)\n",
    "    s,a,r,s_,d = batch\n",
    "    if rewardtype.casefold() == 'RND'.casefold():\n",
    "        r = RND_reward(s,a)\n",
    "    Qpreds = Qnetwork(s)\n",
    "    #action number to onehot encoding\n",
    "    a_mask = torch.nn.functional.one_hot(a,num_classes=params.nA).squeeze(dim=1)\n",
    "\n",
    "    Qpred =torch.max(Qpreds*a_mask,dim=1,keepdim=True)[0]\n",
    "    Qpred = Qpred.squeeze()\n",
    "\n",
    "    Qtarget = (r + params.gamma*torch.max(Qnetwork(s_),dim=1,keepdim=True)[0])\n",
    "    Qtarget = Qtarget.squeeze()\n",
    "    \n",
    "    loss = torch.mean((Qpred-Qtarget)**2)\n",
    "    Qnetwork.optim.zero_grad()\n",
    "    loss.backward()\n",
    "    Qnetwork.optim.step()\n",
    "\n",
    "    return Qnetwork, loss\n",
    "   \n",
    "\n",
    "\n",
    "#s2 = np.stack((s,s_,s_),axis=0)\n",
    "Q1 = Qnet(params)\n",
    "#x = Q.forward(s)\n",
    "#x = Q.forward(s2)\n",
    "\n",
    "#Make sure action selection works\n",
    "Q2 = Qnet(params)\n",
    "state = torch.tensor(stest).unsqueeze(dim=0)\n",
    "#printo('state'); printo('state.size()')\n",
    "for _ in range(4):\n",
    "    #Qs = Qs_(state,Q1)\n",
    "    Qs = Qs_mix(state,Q1,Q2,alpha=0.9)\n",
    "    action = choose_action(Qs,epsilon=0.1,mode='proportional')\n",
    "    printo('action')    \n",
    "\n",
    "\n",
    "\n",
    "#Grab samples from buffer\n",
    "s,a,r,s_,d = buffer.sample(batch=1)\n",
    "#Modify Reward\n",
    "#Recompile\n",
    "batch_ = s,a,r,s_,d\n",
    "Q1, loss = updateQ(Q1,params,batch_)\n",
    "\n",
    "#Grab samples from buffer\n",
    "s,a,r,s_,d = buffer.sample_recent(batch=1)\n",
    "#batch = buffer.sample(batch=4)\n",
    "\n",
    "RND_target = RNDnet(params)\n",
    "RND = RNDnet(params)\n",
    "\n",
    "for iter in range(200):\n",
    "    #Grab samples from buffer\n",
    "    s,a,r,s_,d = buffer.sample_recent(batch=10)\n",
    "    with torch.no_grad():\n",
    "        vec1 = RND_target(s)\n",
    "        #print(vec1)\n",
    "        vec2 = RND(s)\n",
    "        #print(vec2)\n",
    "        distance = torch.sqrt(torch.sum((vec1-vec2)**2,dim=1))\n",
    "        #print(distance)\n",
    "    batch = buffer.sample_recent()\n",
    "    RNDnetwork, loss = updateRND(RND_target,RND,params,batch)\n",
    "    print('iter = ',iter,' loss = ', loss,' distance = ',torch.mean(distance))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6487212707001282 0.6065306597126334\n",
      "0.731058578630005\n"
     ]
    }
   ],
   "source": [
    "aa = np.exp(6/12)\n",
    "bb = np.exp(-6/12)\n",
    "print(aa,bb)\n",
    "print(aa/(aa+bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionspace Discrete(3)\n",
      "observationspace Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "env.observation_space.shape (2,)\n",
      "env.action_space.n 3\n",
      "dims (4, 2)\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "deque([array([[3, 4],\n",
      "       [6, 7]]), array([1, 2])], maxlen=5)\n",
      "d 9\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/luticor/anaconda3/envs/torchenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3444\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/tmp/ipykernel_7658/1000968240.py\"\u001b[0m, line \u001b[1;32m28\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    printo('testdeque(0:1)')\n",
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_7658/3767072933.py\"\u001b[0;36m, line \u001b[0;32m34\u001b[0;36m, in \u001b[0;35mprinto\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(string,eval(string))\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    testdeque(0:1)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "actionspace = env.action_space\n",
    "observationspace = env.observation_space\n",
    "env.close()\n",
    "\n",
    "printo('actionspace')\n",
    "printo('observationspace')\n",
    "printo('env.observation_space.shape')\n",
    "printo('env.action_space.n')\n",
    "dims = env.observation_space.shape\n",
    "dims = (4,) + dims\n",
    "printo('dims')\n",
    "a = np.zeros(shape = (dims))\n",
    "print(a)\n",
    "\n",
    "\n",
    "testdeque = deque(maxlen=5)\n",
    "b = np.array([[3,4],[6,7]])\n",
    "c = np.array([1,2])\n",
    "testdeque.append(b)\n",
    "testdeque.append(c)\n",
    "print(testdeque)\n",
    "\n",
    "#d = np.random.choice(np.array(range(10)))\n",
    "d = np.random.choice(range(10))\n",
    "printo('d')\n",
    "\n",
    "printo('testdeque(0:1)')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f5189addcb6857fb6010c7331b78e3788874ab921e2d657aa05e85d4165bc61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torchenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
